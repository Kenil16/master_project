11/09/2020:
The day has been spend on litterature search. A number of articles were found which is going to be used in the related work section of the report. 

12/09/2020:
PX4 has been installed. Moreover, a 3D model of the aruco markers has been made. However, the model could not be importet into Gazebo. A solution to this must be found. 12/09/2020:

16/09/2020:
The drone to be used in this project has been implemented as well as the optitrack world in Gazebo. 

04/10/2020:
Arcuo marker detection has been finished where the correct pose from the drone to the marker has been found. Much time has been spend in getting this pose estimation to work proberly. 
This was due to the transformation matrices were not calculated correctly. The ROS method euler_from_matrix(T_drone_marker,'sxyz') was used instead of euler_from_matrix(T_drone_marker,'rxyz'). 
This caused the caulculations to be done wrongly. Also T_drone_camera = euler_matrix(-np.pi/2, np.pi/2,0,'rxyz') np.pi/2 was used instaed of 1.5 which also was a problem. 
Kalman Filters have been implemented for the pose. Maybe better choices of VAR could be found for even better tracking. 

24/10/2020:
Waypoint check fixed. For some reason subcribing to setpoint_local does not work. Strange errors were seen when the local pose of the uav where set to be equal to the wanted setpoint which resultet in that the waypoint check where accomplished strait away. Here changing the waypoint check where the wanted pos where given as input fixed the problem.

26/10/2020:
Kalman filter changed to trust new marker poses more to get a more dynamic update of marker poses in respect to the drone. This solved the problem of vision based navigation in PX4. However, the velocity in the z direction is above max. This could be because of the GPS (Vision pose estimate in the z direction) having a too big variance. This could be solved by using a aruco board for higher precision. This is due to the sensor fusion with IMU, GPS etc. 

2/11/2020:
Marker detection is working with aruco board. However, some of the detected markers in the aruco board seems to be hard to detect. Bigger separation between arucos in the board yeilds higher presicion. This can be due to the arrancement of the aruco on the wall model. The top of the world model should be bigger so that a higher difference between the board and background is made. Cameras uses lot of CPU - Try to lower the cam resolution.

03/10/2020:
ArUco detection for both front and bottom cam works now. However, there seems to be probelms with the translation vector from pose estimation. Here a opposite sign error in the x direction wa observed. This must be fixed! The problem is from the pose from aruco to camera.

04/11/2020:
Pose estimation from aruco to camrera works fine. However, different configurations in regard to the drone control for the front and bottom cam must be set. First step in order to navigate the drone beetween the markers have been made. Here linear interpolation between the waypoints should be used to insure a stabile flight and speed of the drone.

06/11/2020:
First drone navigation between markers performed. However, a fixed speed must be made which is now varying a lot between waypoints. Now the x coordinate is increased by one meter every time a new marker (local coordinate system) is detected. This is done to insure a smooth transition between waypoints which also yiels better stability for the drone. Maybe another solution should be found. 

07/11/2020:
Transformation matrix from camera to drone is wrong somehow!This must be fixed

09/11/2020:
Transformation matrix fixed. Appranthly, the cam orientaion was inverted in respect to the x axis. Normally x is positive horisontally, y positive vertically and z the depth. Here x is inverted yieldig a rotaion matrix of (180,180,0) instead of (0,180,0) in roll, pitch yaw respectivly in regard of the drone to the cam.

10/11/2020:
First iteration of moving between waypoints completed. This first approach takes into account the local coordinate system of each aruco marker. When the drone sees a new aruco board the 'global' coordinate system is increased or decreased by the amount of meters which seperates the markers placed on the ground. This effectively insures a smooth transition betweem the markers and there coordinate system. The drone can be set to move forward, backwards, left or right according to the markers placed on the ground. When moving out to the world the list of markers, movements and waypoints is just reverted. However, the regulation must be tuned because the position control works quite bad at the moment.

Future work:
	* Use the IMU data for position control of the drone (Remember to take drift of this estimation into account). 
	* When the IMU data is used the markers can be used to navigate the drone in a giving direction according to the orientation of the marker. 
	* Moreover, sensor funsion using both IMU and camera data could be used to improve the stabillity of the position control of the drone (Maybe using an Extended Kalman filter).
	From meeting with Henrik:
		* Consider to use only a single aruco board as a sort of global coordinate system. This could be a 100*100 aruco board. Using this no shifting between coordinate systems is done. This 		  could insure a more presice pose estimation as well as better estimation in regard to the PX4 flight control.
		* The test with the error in the pose estimation by the amount of distance from the aruco using interpolation, could also involve how much the aruco board fills out the image of the 			  camera. Here the hypothesis would be, that the more the board occupies in the image frame, the better the pose estimation of the board will be. 
		* Make tests of using bottom cam along, front cam along and both of them for the pose estimation. Give pros and cons from the methods used to summarize which solution could be the best for 			  a given scenario (maybe from a bunsiness's point of view).        
	
Todo:
	* Remember to fix the transformation matrix between the front camera and the drone for the front camera. 
	* The methods in regard to the offset for the x,y and z axis in the aruco pos estimation should be moved away from the marker detection scripts to another place e.g. autonoumous flight. 
	* Hence the detected aruco IDs could be published instead from the marker detection script.
	* Remember to also make a small function to calculate the wanted angle from the giving movements.

05/01/2021:
Final first iteration of the simulation map has been completed. Here a 3d map with a one way opening has been made where the road branches in 3 different directions. It has been tested in all directions and it works quite nice. However, the drone has been found to be quite unstable in keeping its pos in the x and y direction when hovering above a board. This can be due to either a bad chosen PID parameters but more likely the estimated pose estimation from aruco board estimation. A bad camera calibration is not posible because the distortion parameters for the camera have been inizialied ti 0.

06/01/2020:
PID for position has been implemented. However, some issues with the GPS to vision test where it does not change pos has been detected. Tests with the resolution of the cam has been made. Higher resolution yeilds better aruco detection but lower FPS which seems to make the pose control unstable. 
